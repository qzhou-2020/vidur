cluster_config:
  num_replicas: 1

replica_config:
  device: a100
  model_name: meta-llama/Llama-2-7b-hf
  tensor_parallel_size: 1
  num_pipeline_stages: 1

request_generator_config:
  type: synthetic
synthetic_request_generator_config:
  num_requests: 128

# alternative: zipf, uniform, fixed
# if alternative is selected, trace_file is not needed.
length_generator_config:
  type: trace 
trace_request_length_generator_config:
  max_tokens: 4096
  trace_file: ./data/processed_traces/arxiv_summarization_stats_llama2_tokenizer_filtered_v2.csv

interval_generator_config:
  type: static

# alternative: lightllm, orca, faster_transformer, sarathi
replica_scheduler_config:
  type: vllm
vllm_scheduler_config:
  # batch size cap is needed for all alternative
  batch_size_cap: 256
  # max tokens is needed for vllm and lightllm
  max_tokens_in_batch: 4096